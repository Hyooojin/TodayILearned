{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "★ **Writing Mathematic 참고 페이지**: [http://csrgxtu.github.io/2015/03/20/Writing-Mathematic-Fomulars-in-Markdown/](http://csrgxtu.github.io/2015/03/20/Writing-Mathematic-Fomulars-in-Markdown/)\n",
    "\n",
    "\n",
    "```\n",
    "(예시)\n",
    "어떤 학생이 몇시간 공부했더니 얼마 정도의 성적이 나오더라\n",
    "```\n",
    "* supervised learning\n",
    "> **x, y의 데이터를 가지고** 학습을 시킨다.\n",
    "\n",
    "최종적인 목표는 0 ~ 100점 사이의 스코어 **범위를 예측**한다. \n",
    "\n",
    "* regression\n",
    "> 범위를 예측시키는것은, 이런 형태의 머신러닝을 supervised learning중에서도 regression이라고 한다.\n",
    "\n",
    "* training\n",
    "> 이미 나온 데이터를 가지고 학습을 시키는 과정을 training이라고 하며, 그 training에 쓰이는 데이터를 training data라고 한다. \n",
    "\n",
    "* regression모델\n",
    "> regression모델이 training data를 가지고 학습을 하면, \n",
    "어떤 모델을 만든다. 모델이 만들어졌다는 것은 학습이 끝났다는 것을 뜻한다.\n",
    "\n",
    "* regression을 사용한다는 것?\n",
    "> \"어떤 학생이 7시간 공부했는데 몇점이나 받을 수 있겠니?\" 하고 기계한테 물어보면, regression은 학습된 것으로 기반으로 리턴값(y)를 출력해준다.\n",
    "\n",
    "\n",
    "\\* **[회귀분석(regression)](https://ko.wikipedia.org/wiki/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D): ** 통계학에서, 회귀분석(回歸分析, 영어: regression analysis)은 <u>관찰된 연속형 변수들에 대해 두 변수 사이의 모형을 구한뒤 적합도를 측정해 내는 분석 방법</u>이다.\n",
    "\n",
    "* regression 모델을 학습한다는 것?\n",
    "> <u>**하나의 가설을 세울 필요가 있다.**</u> <br>\n",
    "\"우리 데이터에 대해서 잘 모르겠지만, **이런 형태로 맞을꺼야!!**\"\n",
    ">> Linear(라는 이름이 붙여진다면,)한 모델이 우리 데이터에 맞을꺼다.\n",
    "\n",
    "\\* **[선형(linear)](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95%EC%84%B1): **  <u> **직선처럼** 똑바른 도형, 또는 그와 비슷한 성질을 갖는 대상</u>이라는 뜻으로, 이러한 성질을 갖고 있는 변환 등에 대하여 쓰는 용어이다. **함수의 경우**, <u>어떠한 함수가 진행하는 모양이 '직선'이라는 의미로 사용</u>된다. 이러한 개념은 수학, 물리학 등에서 많이 사용된다. 다른 말로 1차(一次)라고도 한다. (단어 '1차' 자체는, '선형'을 의미하지 않는 경우도 많다.)\n",
    "\n",
    "```\n",
    "(예시)\n",
    "공부를 많이하면 할수록, 성적이 올라간다. \n",
    "```\n",
    "\n",
    "**Linear로 설명할 수 있는, Linear로 모델을 세울 수 있는 경우가 많다. **\n",
    "\n",
    "**Linear하게 가설을 세운다는 것은, <u>어떤 데이터가 있다면, 여기에 잘 맞는 Linear한 선을 찾는다는 것이라고 할 수 있다.</u>**<br>\n",
    "**데이터에 알맞는 Linear한 선을 찾는 것이** 학습을 하는 것이다.\n",
    "\n",
    "<br>\n",
    "따라해보자: [Simple AI/ Linear Regression](https://medium.com/simple-ai/linear-regression-intro-to-machine-learning-6-6e320dbdaf06) <br>\n",
    "따라해보자: [머신러닝스터디 4. 회귀분석](https://medium.com/mathpresso/mathpresso-%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D-%EC%8A%A4%ED%84%B0%EB%94%94-4-%ED%9A%8C%EA%B7%80-%EB%B6%84%EC%84%9D-regression-1-6d6cc0aaa483) <br>\n",
    "참고: [김성훈의 교수님의 강의가 정리되어있는 블로그](http://pythonkim.tistory.com/7)<br>\n",
    "참고: [수학포기자를 위한 딥러닝 로지스틱 회귀를 이용한 분류 모델](http://bcho.tistory.com/1142)<br>\n",
    "라이브러리: [python/scikit/linearregression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)<br>\n",
    "참고: [ML 01:LINIREAR REGRESSION](http://1ambda.github.io/data-analysis/machine-learning-week-1/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Linear) Hypothesis\n",
    "\\\\(H(x) = Wx + b\\\\) <br>\n",
    "**주어진 x값에 대해서 예측을 어떻게 할 것인가가 Hypothesis**\n",
    "\\\\(h_{\\Theta}x = \\Theta_{0} + \\Theta_{1}x\\\\)\n",
    "\n",
    "<img src=http://mercris.files.wordpress.com/2012/07/screen-shot-2012-07-17-at-2-12-05-pm.png?w=584>\n",
    "[https://mercris.files.wordpress.com/2012/07/screen-shot-2012-07-17-at-2-12-05-pm.png?w=584](https://mercris.files.wordpress.com/2012/07/screen-shot-2012-07-17-at-2-12-05-pm.png?w=584)\n",
    "\n",
    "* Which hypothesis is better?\n",
    "여러개 그어진 linear한 선 중에서, **어떤 선이 우리가 가지고 있는 데이터와 <u>가장 가까운 선인가?</u>** \n",
    "\n",
    "* cost function, loss function, 거리로 측정\n",
    "실제 데이터와 가설이 나타내는 데이터 점의 거리가 멀면 나쁜것, 거기가 가까우면 좋은것\n",
    "> 우리가 세운 가설과 실제 데이터가 얼마나 다른가를 나타낸다.<br>\n",
    "cost function->  \\\\({(H(x)-y)}^{2}\\\\)\n",
    "<br><br>\n",
    "normal하게 표현하면, <br>\n",
    "\n",
    "\\\\(cost(W, b)\\\\) = \\\\(\\frac{1}{m}\\sum_{i=1}^{m} (H(x^i)-y^i)^2\\\\) <br>\n",
    "<br>\n",
    "\\\\(J(\\Theta_{0}, \\Theta_{1})\\\\) =\n",
    "\n",
    "<img src=\"http://s0.wp.com/latex.php?latex=J%28%5Ctheta_%7B0%7D%2C+%5Ctheta_%7B1%7D%29+%3D+%5Cdfrac+%7B1%7D%7B2m%7D+%5Csum+%5Climits_%7Bi%3D1%7D%5E%7Bm%7D+%28h_%7B%5Ctheta%7D+%28x%5E%7B%28i%29%7D%29+-+y%5E%7B%28i%29%7D%29%5E2&bg=ffffff&fg=333333&s=0\">\n",
    "\n",
    "[http://www.holehouse.org/](http://www.holehouse.org/](http://www.holehouse.org/](http://www.holehouse.org/)\n",
    "<br>\n",
    "```\n",
    "이 식을 cost function 또는 squred error function 이라 부른다. 여기서 1/2m 으로 나누는 이유에 대해 좀 궁금해서 구글링 해봤는데, 1/m 으로 나누는 이유는 squared error 에 대해 mean 을 얻기 위한거고, 1/2 로 다시 나누는 이유는 미분했을때 나오는 2 를 제거하기 위해서다.\n",
    "```\n",
    "출저: [http://1ambda.github.io/data-analysis/machine-learning-week-1/](http://1ambda.github.io/data-analysis/machine-learning-week-1/)\n",
    "\n",
    "##### W, b가 달라질 수록 cost function은 커질수도 작아질 수 있다. 즉, W, b를 조정해서 cost function을 가장 작은 사이즈로 조정하는 것을 `학습`이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. graph 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\\\(H(x) = Wx + b\\\\) <br>\n",
    "variable로 정의할 수 있다. <br>\n",
    "여기서 variable은 기존의 프로그램에서의 변수와 다른 의미이다. <br>\n",
    "* **텐서플로우가 사용하는 Variable = tensorflow가 자체적으로 변경시키는 값 = trainable한 Variable**\n",
    "* 값을 모르니까 random값으로 준다.\n",
    "* tf.random_normal([**shape**])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "hypothesis = x_train * W + b # node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\\\(cost(W, b)\\\\) = \\\\(\\frac{1}{m}\\sum_{i=1}^{m} (H(x^i)-y^i)^2\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_2:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t = [1., 2., 3., 4.]\n",
    "print(tf.reduce_mean(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "# 평균을 내주는 부분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# optimizer 함수 호출\n",
    "train = optimizer.minimize(cost)\n",
    "# minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. session만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# Variable을 사용하기 전에는 global.. \n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**minimize하는 작업, 노드**를 train이라고 하였다.<br>\n",
    "train을 시키면 연결연결되어서 W,b로 연결된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 ==0:\n",
    "        print(step, sess.run(cost), sess.run(W))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
