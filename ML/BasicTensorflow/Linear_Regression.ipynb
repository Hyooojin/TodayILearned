{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "★ **Writing Mathematic 참고 페이지**: [http://csrgxtu.github.io/2015/03/20/Writing-Mathematic-Fomulars-in-Markdown/](http://csrgxtu.github.io/2015/03/20/Writing-Mathematic-Fomulars-in-Markdown/)\n",
    "\n",
    "\n",
    "```\n",
    "(예시)\n",
    "어떤 학생이 몇시간 공부했더니 얼마 정도의 성적이 나오더라\n",
    "```\n",
    "* supervised learning\n",
    "> **x, y의 데이터를 가지고** 학습을 시킨다.\n",
    "\n",
    "최종적인 목표는 0 ~ 100점 사이의 스코어 **범위를 예측**한다. \n",
    "\n",
    "* regression\n",
    "> 범위를 예측시키는것은, 이런 형태의 머신러닝을 supervised learning중에서도 regression이라고 한다.\n",
    "\n",
    "* training\n",
    "> 이미 나온 데이터를 가지고 학습을 시키는 과정을 training이라고 하며, 그 training에 쓰이는 데이터를 training data라고 한다. \n",
    "\n",
    "* regression모델\n",
    "> regression모델이 training data를 가지고 학습을 하면, \n",
    "어떤 모델을 만든다. 모델이 만들어졌다는 것은 학습이 끝났다는 것을 뜻한다.\n",
    "\n",
    "* regression을 사용한다는 것?\n",
    "> \"어떤 학생이 7시간 공부했는데 몇점이나 받을 수 있겠니?\" 하고 기계한테 물어보면, regression은 학습된 것으로 기반으로 리턴값(y)를 출력해준다.\n",
    "\n",
    "\n",
    "\\* **[회귀분석(regression)](https://ko.wikipedia.org/wiki/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D): ** 통계학에서, 회귀분석(回歸分析, 영어: regression analysis)은 <u>관찰된 연속형 변수들에 대해 두 변수 사이의 모형을 구한뒤 적합도를 측정해 내는 분석 방법</u>이다.\n",
    "\n",
    "* regression 모델을 학습한다는 것?\n",
    "> <u>**하나의 가설을 세울 필요가 있다.**</u> <br>\n",
    "\"우리 데이터에 대해서 잘 모르겠지만, **이런 형태로 맞을꺼야!!**\"\n",
    ">> Linear(라는 이름이 붙여진다면,)한 모델이 우리 데이터에 맞을꺼다.\n",
    "\n",
    "\\* **[선형(linear)](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95%EC%84%B1): **  <u> **직선처럼** 똑바른 도형, 또는 그와 비슷한 성질을 갖는 대상</u>이라는 뜻으로, 이러한 성질을 갖고 있는 변환 등에 대하여 쓰는 용어이다. **함수의 경우**, <u>어떠한 함수가 진행하는 모양이 '직선'이라는 의미로 사용</u>된다. 이러한 개념은 수학, 물리학 등에서 많이 사용된다. 다른 말로 1차(一次)라고도 한다. (단어 '1차' 자체는, '선형'을 의미하지 않는 경우도 많다.)\n",
    "\n",
    "```\n",
    "(예시)\n",
    "공부를 많이하면 할수록, 성적이 올라간다. \n",
    "```\n",
    "\n",
    "**Linear로 설명할 수 있는, Linear로 모델을 세울 수 있는 경우가 많다. **\n",
    "\n",
    "**Linear하게 가설을 세운다는 것은, <u>어떤 데이터가 있다면, 여기에 잘 맞는 Linear한 선을 찾는다는 것이라고 할 수 있다.</u>**<br>\n",
    "**데이터에 알맞는 Linear한 선을 찾는 것이** 학습을 하는 것이다.\n",
    "\n",
    "<br>\n",
    "따라해보자: [Simple AI/ Linear Regression](https://medium.com/simple-ai/linear-regression-intro-to-machine-learning-6-6e320dbdaf06) <br>\n",
    "따라해보자: [머신러닝스터디 4. 회귀분석](https://medium.com/mathpresso/mathpresso-%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D-%EC%8A%A4%ED%84%B0%EB%94%94-4-%ED%9A%8C%EA%B7%80-%EB%B6%84%EC%84%9D-regression-1-6d6cc0aaa483) <br>\n",
    "참고: [김성훈의 교수님의 강의가 정리되어있는 블로그](http://pythonkim.tistory.com/7)<br>\n",
    "참고: [수학포기자를 위한 딥러닝 로지스틱 회귀를 이용한 분류 모델](http://bcho.tistory.com/1142)<br>\n",
    "라이브러리: [python/scikit/linearregression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)<br>\n",
    "참고: [ML 01:LINIREAR REGRESSION](http://1ambda.github.io/data-analysis/machine-learning-week-1/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Linear) Hypothesis\n",
    "\\\\(H(x) = Wx + b\\\\) <br>\n",
    "**주어진 x값에 대해서 예측을 어떻게 할 것인가가 Hypothesis**\n",
    "\\\\(h_{\\Theta}x = \\Theta_{0} + \\Theta_{1}x\\\\)\n",
    "\n",
    "<img src=http://mercris.files.wordpress.com/2012/07/screen-shot-2012-07-17-at-2-12-05-pm.png?w=584>\n",
    "[https://mercris.files.wordpress.com/2012/07/screen-shot-2012-07-17-at-2-12-05-pm.png?w=584](https://mercris.files.wordpress.com/2012/07/screen-shot-2012-07-17-at-2-12-05-pm.png?w=584)\n",
    "\n",
    "* Which hypothesis is better?\n",
    "여러개 그어진 linear한 선 중에서, **어떤 선이 우리가 가지고 있는 데이터와 <u>가장 가까운 선인가?</u>** \n",
    "\n",
    "* cost function, loss function, 거리로 측정\n",
    "실제 데이터와 가설이 나타내는 데이터 점의 거리가 멀면 나쁜것, 거기가 가까우면 좋은것\n",
    "> 우리가 세운 가설과 실제 데이터가 얼마나 다른가를 나타낸다.<br>\n",
    "cost function->  \\\\({(H(x)-y)}^{2}\\\\)\n",
    "<br><br>\n",
    "normal하게 표현하면, <br>\n",
    "\n",
    "\\\\(cost(W, b)\\\\) = \\\\(\\frac{1}{m}\\sum_{i=1}^{m} (H(x^i)-y^i)^2\\\\) <br>\n",
    "<br>\n",
    "\\\\(J(\\Theta_{0}, \\Theta_{1})\\\\) =\n",
    "\n",
    "<img src=\"http://s0.wp.com/latex.php?latex=J%28%5Ctheta_%7B0%7D%2C+%5Ctheta_%7B1%7D%29+%3D+%5Cdfrac+%7B1%7D%7B2m%7D+%5Csum+%5Climits_%7Bi%3D1%7D%5E%7Bm%7D+%28h_%7B%5Ctheta%7D+%28x%5E%7B%28i%29%7D%29+-+y%5E%7B%28i%29%7D%29%5E2&bg=ffffff&fg=333333&s=0\">\n",
    "\n",
    "[http://www.holehouse.org/](http://www.holehouse.org/](http://www.holehouse.org/](http://www.holehouse.org/)\n",
    "<br>\n",
    "```\n",
    "이 식을 cost function 또는 squred error function 이라 부른다. 여기서 1/2m 으로 나누는 이유에 대해 좀 궁금해서 구글링 해봤는데, 1/m 으로 나누는 이유는 squared error 에 대해 mean 을 얻기 위한거고, 1/2 로 다시 나누는 이유는 미분했을때 나오는 2 를 제거하기 위해서다.\n",
    "```\n",
    "출저: [http://1ambda.github.io/data-analysis/machine-learning-week-1/](http://1ambda.github.io/data-analysis/machine-learning-week-1/)\n",
    "\n",
    "##### W, b가 달라질 수록 cost function은 커질수도 작아질 수 있다. 즉, W, b를 조정해서 cost function을 가장 작은 사이즈로 조정하는 것을 `학습`이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. graph 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\\\(H(x) = Wx + b\\\\) <br>\n",
    "variable로 정의할 수 있다. <br>\n",
    "여기서 variable은 기존의 프로그램에서의 변수와 다른 의미이다. <br>\n",
    "* **텐서플로우가 사용하는 Variable = tensorflow가 자체적으로 변경시키는 값 = trainable한 Variable**\n",
    "* 값을 모르니까 random값으로 준다.\n",
    "* tf.random_normal([**shape**])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "hypothesis = x_train * W + b # node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\\\(cost(W, b)\\\\) = \\\\(\\frac{1}{m}\\sum_{i=1}^{m} (H(x^i)-y^i)^2\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_2:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t = [1., 2., 3., 4.]\n",
    "print(tf.reduce_mean(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "# 평균을 내주는 부분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# optimizer 함수 호출\n",
    "train = optimizer.minimize(cost)\n",
    "# minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. session만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# Variable을 사용하기 전에는 global.. \n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**minimize하는 작업, 노드**를 train이라고 하였다.<br>\n",
    "train을 시키면 연결연결되어서 W,b로 연결된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17.579319 [-1.2386743] [0.70399326]\n",
      "20 0.41764104 [0.25290775] [1.2807759]\n",
      "40 0.23833752 [0.4200277] [1.2786555]\n",
      "60 0.21518372 [0.45985416] [1.2240926]\n",
      "80 0.19542176 [0.48643598] [1.1670913]\n",
      "100 0.1774851 [0.51068556] [1.1122925]\n",
      "120 0.1611948 [0.53369236] [1.0600238]\n",
      "140 0.14639966 [0.5556081] [1.0102069]\n",
      "160 0.13296251 [0.576493] [0.96273094]\n",
      "180 0.120758675 [0.59639627] [0.9174861]\n",
      "200 0.10967496 [0.6153642] [0.8743676]\n",
      "220 0.09960855 [0.6334407] [0.8332755]\n",
      "240 0.09046611 [0.6506676] [0.79411465]\n",
      "260 0.082162715 [0.66708493] [0.7567941]\n",
      "280 0.074621536 [0.6827308] [0.7212277]\n",
      "300 0.06777248 [0.69764113] [0.6873327]\n",
      "320 0.06155205 [0.71185094] [0.65503055]\n",
      "340 0.0559026 [0.7253928] [0.6242467]\n",
      "360 0.050771613 [0.73829836] [0.59490937]\n",
      "380 0.04611164 [0.75059736] [0.56695086]\n",
      "400 0.041879326 [0.7623183] [0.5403063]\n",
      "420 0.03803545 [0.7734885] [0.5149139]\n",
      "440 0.034544438 [0.7841337] [0.4907149]\n",
      "460 0.03137381 [0.79427856] [0.46765316]\n",
      "480 0.028494185 [0.80394673] [0.44567516]\n",
      "500 0.025878867 [0.81316054] [0.42473006]\n",
      "520 0.023503615 [0.82194126] [0.40476936]\n",
      "540 0.021346373 [0.83030933] [0.38574672]\n",
      "560 0.019387104 [0.83828413] [0.3676181]\n",
      "580 0.017607694 [0.84588426] [0.35034138]\n",
      "600 0.015991589 [0.85312706] [0.33387664]\n",
      "620 0.014523812 [0.8600296] [0.3181857]\n",
      "640 0.013190765 [0.86660767] [0.30323213]\n",
      "660 0.011980053 [0.87287664] [0.28898132]\n",
      "680 0.010880488 [0.8788509] [0.2754003]\n",
      "700 0.009881818 [0.8845445] [0.26245755]\n",
      "720 0.008974835 [0.8899705] [0.25012296]\n",
      "740 0.008151102 [0.8951415] [0.2383681]\n",
      "760 0.0074029504 [0.9000695] [0.22716568]\n",
      "780 0.006723478 [0.9047658] [0.21648975]\n",
      "800 0.0061063743 [0.90924156] [0.20631552]\n",
      "820 0.0055458974 [0.9135068] [0.1966194]\n",
      "840 0.005036874 [0.9175716] [0.18737902]\n",
      "860 0.004574567 [0.9214455] [0.17857291]\n",
      "880 0.004154704 [0.9251373] [0.17018063]\n",
      "900 0.0037733607 [0.92865545] [0.16218278]\n",
      "920 0.0034270287 [0.93200845] [0.15456079]\n",
      "940 0.003112483 [0.93520385] [0.14729701]\n",
      "960 0.0028268073 [0.93824905] [0.14037459]\n",
      "980 0.0025673544 [0.9411511] [0.13377748]\n",
      "1000 0.0023317116 [0.9439167] [0.12749045]\n",
      "1020 0.0021176988 [0.9465524] [0.12149888]\n",
      "1040 0.0019233333 [0.94906414] [0.11578892]\n",
      "1060 0.0017467928 [0.95145804] [0.11034725]\n",
      "1080 0.0015864647 [0.9537393] [0.10516135]\n",
      "1100 0.0014408556 [0.95591336] [0.1002192]\n",
      "1120 0.0013086089 [0.95798534] [0.09550928]\n",
      "1140 0.0011885006 [0.9599598] [0.09102075]\n",
      "1160 0.0010794217 [0.9618415] [0.08674312]\n",
      "1180 0.0009803494 [0.96363485] [0.08266652]\n",
      "1200 0.0008903655 [0.9653439] [0.07878147]\n",
      "1220 0.0008086417 [0.9669726] [0.07507902]\n",
      "1240 0.00073441956 [0.96852475] [0.07155059]\n",
      "1260 0.0006670165 [0.970004] [0.06818803]\n",
      "1280 0.0006057906 [0.97141373] [0.06498342]\n",
      "1300 0.00055018876 [0.97275716] [0.06192941]\n",
      "1320 0.00049969164 [0.97403747] [0.05901897]\n",
      "1340 0.00045382627 [0.97525764] [0.05624525]\n",
      "1360 0.0004121744 [0.9764204] [0.05360193]\n",
      "1380 0.0003743429 [0.9775286] [0.05108285]\n",
      "1400 0.00033998318 [0.9785846] [0.04868217]\n",
      "1420 0.0003087787 [0.97959095] [0.04639432]\n",
      "1440 0.00028043846 [0.9805502] [0.04421398]\n",
      "1460 0.00025470092 [0.98146427] [0.04213606]\n",
      "1480 0.00023132133 [0.98233545] [0.0401558]\n",
      "1500 0.00021009009 [0.9831656] [0.03826861]\n",
      "1520 0.00019080646 [0.98395675] [0.03647012]\n",
      "1540 0.00017329115 [0.9847108] [0.03475612]\n",
      "1560 0.0001573868 [0.9854293] [0.03312267]\n",
      "1580 0.00014294135 [0.986114] [0.03156602]\n",
      "1600 0.00012982207 [0.98676664] [0.03008256]\n",
      "1620 0.00011790668 [0.98738855] [0.02866878]\n",
      "1640 0.00010708502 [0.98798126] [0.02732144]\n",
      "1660 9.7255535e-05 [0.988546] [0.02603743]\n",
      "1680 8.832835e-05 [0.98908436] [0.02481379]\n",
      "1700 8.0222155e-05 [0.9895974] [0.02364762]\n",
      "1720 7.2857794e-05 [0.9900864] [0.02253625]\n",
      "1740 6.617209e-05 [0.9905523] [0.02147706]\n",
      "1760 6.0097507e-05 [0.99099624] [0.02046769]\n",
      "1780 5.458076e-05 [0.99141943] [0.01950577]\n",
      "1800 4.957236e-05 [0.99182266] [0.01858905]\n",
      "1820 4.5021487e-05 [0.992207] [0.01771543]\n",
      "1840 4.0889292e-05 [0.9925732] [0.01688285]\n",
      "1860 3.7136182e-05 [0.99292225] [0.01608941]\n",
      "1880 3.3728254e-05 [0.99325484] [0.01533329]\n",
      "1900 3.0631847e-05 [0.9935719] [0.01461266]\n",
      "1920 2.7820759e-05 [0.99387395] [0.01392591]\n",
      "1940 2.5267558e-05 [0.9941619] [0.01327145]\n",
      "1960 2.294821e-05 [0.99443626] [0.01264774]\n",
      "1980 2.0841757e-05 [0.9946977] [0.01205334]\n",
      "2000 1.8929031e-05 [0.99494684] [0.0114869]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 ==0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tensor image](tensorimg.png \"tensor\")\n",
    "train만 실행시킨다는 의미는 **그래프를 따라 들어가서 W, b의 값을 조정할 수 있다는 의미** <br>\n",
    "이때 학습이 일어나게 되고, cost와 W, b의 값이 어떻게되는지 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "0 7.2130203 [1.2073979] [-1.703354]\n",
      "20 0.20484729 [1.519349] [-1.1806024]\n",
      "40 0.12628807 [1.4077796] [-0.92697877]\n",
      "60 0.0778564 [1.3201779] [-0.7278398]\n",
      "80 0.047998365 [1.2513956] [-0.5714811]\n",
      "100 0.02959094 [1.1973892] [-0.44871226]\n",
      "120 0.018242776 [1.1549851] [-0.3523174]\n",
      "140 0.011246641 [1.1216903] [-0.27663052]\n",
      "160 0.0069335364 [1.095548] [-0.2172032]\n",
      "180 0.0042745206 [1.0750219] [-0.17054224]\n",
      "200 0.0026352338 [1.0589052] [-0.13390543]\n",
      "220 0.0016246252 [1.0462509] [-0.10513914]\n",
      "240 0.0010015763 [1.0363151] [-0.08255263]\n",
      "260 0.0006174725 [1.0285137] [-0.06481826]\n",
      "280 0.00038067004 [1.0223882] [-0.05089362]\n",
      "300 0.00023468293 [1.0175786] [-0.03996036]\n",
      "320 0.00014468103 [1.0138023] [-0.03137582]\n",
      "340 8.919481e-05 [1.0108372] [-0.02463547]\n",
      "360 5.4988388e-05 [1.008509] [-0.01934314]\n",
      "380 3.3900335e-05 [1.0066811] [-0.01518776]\n",
      "400 2.0900074e-05 [1.0052458] [-0.01192507]\n",
      "420 1.2885536e-05 [1.0041189] [-0.00936335]\n",
      "440 7.943765e-06 [1.0032341] [-0.00735188]\n",
      "460 4.897369e-06 [1.0025394] [-0.00577259]\n",
      "480 3.0192168e-06 [1.0019938] [-0.00453244]\n",
      "500 1.8612045e-06 [1.0015655] [-0.00355869]\n",
      "520 1.147591e-06 [1.0012292] [-0.00279421]\n",
      "540 7.073483e-07 [1.0009651] [-0.0021939]\n",
      "560 4.361989e-07 [1.0007578] [-0.0017227]\n",
      "580 2.689368e-07 [1.000595] [-0.00135264]\n",
      "600 1.6572871e-07 [1.0004672] [-0.00106203]\n",
      "620 1.0220015e-07 [1.0003669] [-0.00083392]\n",
      "640 6.302279e-08 [1.0002881] [-0.00065483]\n",
      "660 3.8892736e-08 [1.0002263] [-0.00051428]\n",
      "680 2.3969472e-08 [1.0001776] [-0.00040381]\n",
      "700 1.4772847e-08 [1.0001395] [-0.00031706]\n",
      "720 9.105199e-09 [1.0001096] [-0.00024894]\n",
      "740 5.610783e-09 [1.000086] [-0.00019545]\n",
      "760 3.4608405e-09 [1.0000675] [-0.00015347]\n",
      "780 2.130368e-09 [1.000053] [-0.00012049]\n",
      "800 1.3151636e-09 [1.0000417] [-9.46318e-05]\n",
      "820 8.149878e-10 [1.0000327] [-7.430265e-05]\n",
      "840 5.027149e-10 [1.0000256] [-5.844383e-05]\n",
      "860 3.103461e-10 [1.0000203] [-4.594474e-05]\n",
      "880 1.9095718e-10 [1.0000159] [-3.6088124e-05]\n",
      "900 1.1822603e-10 [1.0000125] [-2.8333563e-05]\n",
      "920 7.3725914e-11 [1.0000099] [-2.239297e-05]\n",
      "940 4.5651188e-11 [1.0000076] [-1.7513332e-05]\n",
      "960 2.7081152e-11 [1.0000061] [-1.3635056e-05]\n",
      "980 1.715724e-11 [1.0000046] [-1.07124415e-05]\n",
      "1000 1.0048258e-11 [1.0000037] [-8.391833e-06]\n",
      "1020 6.7655512e-12 [1.0000029] [-6.6513776e-06]\n",
      "1040 4.291678e-12 [1.0000024] [-5.3063004e-06]\n",
      "1060 2.8895404e-12 [1.0000019] [-4.3387186e-06]\n",
      "1080 1.9184654e-12 [1.0000015] [-3.5578967e-06]\n",
      "1100 1.2789769e-12 [1.0000014] [-2.9697974e-06]\n",
      "1120 8.81073e-13 [1.0000012] [-2.4989208e-06]\n",
      "1140 6.6317324e-13 [1.000001] [-2.1154642e-06]\n",
      "1160 4.2277293e-13 [1.0000008] [-1.8035333e-06]\n",
      "1180 4.026409e-13 [1.0000008] [-1.6624683e-06]\n",
      "1200 3.7066647e-13 [1.0000008] [-1.6108111e-06]\n",
      "1220 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1240 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1260 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1280 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1300 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1320 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1340 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1360 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1380 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1400 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1420 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1440 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1460 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1480 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1500 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1520 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1540 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1560 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1580 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1600 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1620 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1640 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1660 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1680 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1700 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1720 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1740 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1760 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1780 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1800 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1820 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1840 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1860 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1880 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1900 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1920 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1940 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1960 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "1980 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "2000 3.410605e-13 [1.0000008] [-1.5790224e-06]\n",
      "[5.000003]\n",
      "[2.5000005]\n",
      "[1.4999996 3.5000012]\n",
      "===============================================\n",
      "0 1.2099977 [1.3300004] [0.10999832]\n",
      "20 0.09605434 [1.1978118] [0.38583666]\n",
      "40 0.04856687 [1.1406577] [0.5921809]\n",
      "60 0.024556255 [1.1000173] [0.7389059]\n",
      "80 0.012416103 [1.0711191] [0.84323734]\n",
      "100 0.006277819 [1.0505705] [0.91742414]\n",
      "120 0.0031741732 [1.0359591] [0.970176]\n",
      "140 0.0016049191 [1.0255693] [1.0076864]\n",
      "160 0.00081147754 [1.0181816] [1.0343587]\n",
      "180 0.00041029672 [1.0129282] [1.0533246]\n",
      "200 0.00020745474 [1.009193] [1.0668105]\n",
      "220 0.00010488916 [1.0065368] [1.0764]\n",
      "240 5.303407e-05 [1.0046481] [1.0832188]\n",
      "260 2.6814794e-05 [1.0033051] [1.0880675]\n",
      "280 1.3557268e-05 [1.0023501] [1.0915153]\n",
      "300 6.8549793e-06 [1.001671] [1.093967]\n",
      "320 3.4663717e-06 [1.0011883] [1.0957099]\n",
      "340 1.75228e-06 [1.0008451] [1.0969493]\n",
      "360 8.862805e-07 [1.0006008] [1.0978308]\n",
      "380 4.4809198e-07 [1.0004272] [1.0984573]\n",
      "400 2.2660606e-07 [1.0003039] [1.098903]\n",
      "420 1.14597015e-07 [1.000216] [1.0992199]\n",
      "440 5.794478e-08 [1.0001537] [1.0994453]\n",
      "460 2.9272542e-08 [1.0001092] [1.0996056]\n",
      "480 1.48307775e-08 [1.0000776] [1.0997194]\n",
      "500 7.500671e-09 [1.0000552] [1.0998003]\n",
      "520 3.7973793e-09 [1.0000393] [1.0998579]\n",
      "540 1.9253548e-09 [1.0000279] [1.099899]\n",
      "560 9.727501e-10 [1.0000199] [1.099928]\n",
      "580 4.913545e-10 [1.0000142] [1.099949]\n",
      "600 2.5180497e-10 [1.00001] [1.0999635]\n",
      "620 1.2655618e-10 [1.0000072] [1.099974]\n",
      "640 6.320988e-11 [1.000005] [1.0999815]\n",
      "660 3.274181e-11 [1.0000036] [1.0999867]\n",
      "680 1.5654677e-11 [1.0000026] [1.0999907]\n",
      "700 8.526513e-12 [1.0000019] [1.0999931]\n",
      "720 4.1836755e-12 [1.0000012] [1.0999954]\n",
      "740 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "760 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "780 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "800 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "820 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "840 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "860 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "880 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "900 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "920 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "940 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "960 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "980 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1000 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1020 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1040 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1060 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1080 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1100 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1120 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1140 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1160 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1180 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1200 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1220 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1240 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1260 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1280 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1300 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1320 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1340 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1360 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1380 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1400 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1420 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1440 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1460 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1480 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1500 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1520 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1540 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1560 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1580 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1600 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1620 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1640 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1660 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1680 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1700 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1720 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1740 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1760 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1780 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1800 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1820 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1840 2.2851055e-12 [1.0000011] [1.0999962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1860 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1880 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1900 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1920 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1940 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1960 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "1980 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "2000 2.2851055e-12 [1.0000011] [1.0999962]\n",
      "[6.1000013]\n",
      "[3.599999]\n",
      "[2.599998 4.6     ]\n"
     ]
    }
   ],
   "source": [
    "# Lab 2 Linear Regression\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "# Try to find values for W and b to compute y_data = W * x_data + b\n",
    "# We know that W should be 1 and b should be 0\n",
    "# But let's use TensorFlow to figure it out\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Now we can use X and Y in place of x_data and y_data\n",
    "# # placeholders for a tensor that will be always fed using feed_dict\n",
    "# See http://stackoverflow.com/questions/36693740/\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"=================================================\")\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train],\n",
    "                 feed_dict={X: [1, 2, 3], Y: [1, 2, 3]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)\n",
    "\n",
    "# Learns best fit W:[ 1.],  b:[ 0]\n",
    "\n",
    "\n",
    "# Testing our model\n",
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))\n",
    "\n",
    "\n",
    "print(\"===============================================\")\n",
    "# Fit the line with new training data\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train],\n",
    "                 feed_dict={X: [1, 2, 3, 4, 5],\n",
    "                            Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)\n",
    "\n",
    "# Testing our model\n",
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========step, cost_val, W_val, b_val=====\n",
      "0 13.288369 [-0.29553396] [-0.4724274]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "20 0.121346466 [0.84582084] [0.02507534]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "40 0.0018854747 [0.95594823] [0.06915468]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "60 0.0007302738 [0.96781486] [0.07021407]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "80 0.0006543403 [0.9702602] [0.06732462]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "100 0.0005942019 [0.9717466] [0.06419967]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "120 0.0005396614 [0.97308296] [0.06118624]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "140 0.0004901315 [0.9743487] [0.05831107]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "160 0.00044514347 [0.97555435] [0.05557071]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "180 0.00040428768 [0.97670317] [0.0529591]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "200 0.0003671817 [0.97779804] [0.05047024]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "220 0.00033348193 [0.9788414] [0.04809835]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "240 0.00030287384 [0.9798356] [0.04583799]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "260 0.00027507325 [0.9807835] [0.04368376]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "280 0.00024982673 [0.9816866] [0.04163074]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "300 0.00022689575 [0.9825473] [0.03967422]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "320 0.00020607124 [0.98336744] [0.03780967]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "340 0.00018715672 [0.98414916] [0.03603275]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "360 0.00016997811 [0.98489416] [0.03433931]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "380 0.00015437823 [0.98560405] [0.03272545]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "400 0.00014020682 [0.98628056] [0.03118748]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "420 0.00012733859 [0.98692536] [0.02972179]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "440 0.00011564984 [0.9875398] [0.02832496]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "460 0.00010503468 [0.9881254] [0.02699377]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "480 9.5395946e-05 [0.98868346] [0.02572516]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "500 8.664e-05 [0.9892152] [0.0245162]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "520 7.868841e-05 [0.98972213] [0.02336403]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "540 7.146429e-05 [0.9902053] [0.02226595]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "560 6.490495e-05 [0.99066556] [0.02121948]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "580 5.894755e-05 [0.99110425] [0.0202222]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "600 5.3536685e-05 [0.9915223] [0.01927179]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "620 4.8622867e-05 [0.9919207] [0.0183661]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "640 4.4159886e-05 [0.99230045] [0.01750294]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "660 4.0107276e-05 [0.9926623] [0.01668036]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "680 3.6425732e-05 [0.9930071] [0.01589645]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "700 3.3083106e-05 [0.9933357] [0.01514938]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "720 3.0046698e-05 [0.99364895] [0.01443741]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "740 2.728796e-05 [0.99394745] [0.01375891]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "760 2.4783643e-05 [0.9942319] [0.01311229]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "780 2.2508806e-05 [0.9945029] [0.01249607]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "800 2.0442982e-05 [0.9947612] [0.01190883]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "820 1.856673e-05 [0.9950074] [0.01134921]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "840 1.6862628e-05 [0.9952421] [0.01081584]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "860 1.5315005e-05 [0.9954657] [0.01030753]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "880 1.3909636e-05 [0.9956788] [0.00982311]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "900 1.263285e-05 [0.99588186] [0.00936148]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "920 1.1473053e-05 [0.9960754] [0.00892153]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "940 1.0420663e-05 [0.9962598] [0.00850227]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "960 9.464226e-06 [0.9964356] [0.00810269]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "980 8.595252e-06 [0.9966031] [0.00772192]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1000 7.8066205e-06 [0.9967627] [0.00735905]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1020 7.0901237e-06 [0.99691486] [0.00701323]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1040 6.4390806e-06 [0.9970598] [0.00668364]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1060 5.8483315e-06 [0.997198] [0.00636956]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1080 5.311618e-06 [0.9973297] [0.00607024]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1100 4.8240404e-06 [0.9974552] [0.00578496]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1120 4.3813016e-06 [0.99757475] [0.00551309]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1140 3.979032e-06 [0.9976888] [0.005254]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1160 3.6137535e-06 [0.99779737] [0.00500707]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1180 3.282186e-06 [0.9979009] [0.00477175]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1200 2.9808982e-06 [0.9979995] [0.00454751]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1220 2.7072429e-06 [0.99809355] [0.0043338]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1240 2.4587478e-06 [0.99818313] [0.00413012]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1260 2.2331108e-06 [0.9982685] [0.00393603]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1280 2.0283114e-06 [0.9983499] [0.00375107]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1300 1.8419613e-06 [0.99842745] [0.00357479]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1320 1.6729592e-06 [0.99850136] [0.0034068]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1340 1.5194445e-06 [0.99857175] [0.00324671]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1360 1.3800912e-06 [0.99863887] [0.00309413]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1380 1.2532952e-06 [0.9987028] [0.00294873]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1400 1.138403e-06 [0.99876374] [0.00281018]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1420 1.0338407e-06 [0.99882185] [0.00267813]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1440 9.389278e-07 [0.99887717] [0.0025523]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1460 8.527798e-07 [0.99893] [0.00243239]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1480 7.7450903e-07 [0.9989802] [0.0023181]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1500 7.035908e-07 [0.9990281] [0.00220917]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1520 6.3886506e-07 [0.99907386] [0.00210538]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1540 5.8032634e-07 [0.9991174] [0.00200644]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1560 5.2704655e-07 [0.9991588] [0.00191214]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1580 4.7867485e-07 [0.9991984] [0.00182231]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1600 4.347643e-07 [0.999236] [0.00173669]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1620 3.948202e-07 [0.9992719] [0.0016551]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1640 3.5860717e-07 [0.999306] [0.00157735]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1660 3.2582957e-07 [0.9993387] [0.00150326]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1680 2.9585397e-07 [0.9993698] [0.00143263]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1700 2.6871479e-07 [0.9993993] [0.00136533]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1720 2.4409027e-07 [0.9994275] [0.00130121]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1740 2.2163562e-07 [0.99945444] [0.00124009]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1760 2.0133223e-07 [0.99948] [0.00118183]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1780 1.8286438e-07 [0.9995044] [0.00112634]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1800 1.6611837e-07 [0.9995277] [0.00107345]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1820 1.5088625e-07 [0.99954987] [0.00102304]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1840 1.3703813e-07 [0.999571] [0.000975]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1860 1.2449529e-07 [0.99959123] [0.00092924]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1880 1.1307293e-07 [0.99961036] [0.00088563]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1900 1.0265675e-07 [0.9996286] [0.00084404]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1920 9.3276185e-08 [0.99964607] [0.0008044]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1940 8.47452e-08 [0.99966276] [0.00076666]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1960 7.69675e-08 [0.99967843] [0.00073068]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1980 6.9909824e-08 [0.99969363] [0.00069637]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "2000 6.349562e-08 [0.99970794] [0.00066373]\n",
      "=========feed_dict={X: [5]}=============\n",
      "[4.9992037]\n",
      "=========feed_dict={X: [2.5]}=============\n",
      "[2.4999337]\n",
      "=========feed_dict={X: [1.5, 3.5]}))=============\n",
      "[1.5002257 3.4996414]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "hypothesis = X * W + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train], \n",
    "                 feed_dict={X: [1, 2, 3], Y: [1, 2, 3]})\n",
    "    if step % 20 == 0:\n",
    "        print(\"==========step, cost_val, W_val, b_val=====\")\n",
    "        print(step, cost_val, W_val, b_val)\n",
    "\n",
    "print(\"=========feed_dict={X: [5]}=============\")\n",
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(\"=========feed_dict={X: [2.5]}=============\")\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(\"=========feed_dict={X: [1.5, 3.5]}))=============\")\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========step, cost_val, W_val, b_val=====\n",
      "0 7.2130203 [2.3222513] [-1.1692626]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "20 0.076475 [1.3097904] [-0.7037172]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "40 0.017600907 [1.1485301] [-0.33764347]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "60 0.0040509207 [1.0712563] [-0.16198236]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "80 0.0009323374 [1.0341847] [-0.07771005]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "100 0.00021457928 [1.0164] [-0.03728088]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "120 4.938722e-05 [1.0078677] [-0.01788535]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "140 1.1366555e-05 [1.0037746] [-0.00858039]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "160 2.6159598e-06 [1.0018109] [-0.00411647]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "180 6.021246e-07 [1.0008688] [-0.00197485]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "200 1.3858663e-07 [1.0004168] [-0.00094742]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "220 3.1919594e-08 [1.0001998] [-0.00045456]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "240 7.3384334e-09 [1.000096] [-0.00021808]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "260 1.6912397e-09 [1.000046] [-0.0001046]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "280 3.886053e-10 [1.0000222] [-5.0099025e-05]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "300 8.979365e-11 [1.0000106] [-2.41114e-05]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "320 2.0454157e-11 [1.0000051] [-1.1582502e-05]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "340 5.1585403e-12 [1.0000024] [-5.5862733e-06]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "360 1.1096309e-12 [1.0000012] [-2.6716066e-06]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "380 2.5105842e-13 [1.0000006] [-1.2768578e-06]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "400 6.158037e-14 [1.0000004] [-6.8081147e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "420 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "440 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "460 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "480 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "500 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "520 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "540 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "560 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "580 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "600 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "620 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "640 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "660 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "680 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "700 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "720 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "740 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "760 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "780 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "800 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "820 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "840 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "860 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "880 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "900 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "920 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "940 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "960 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "980 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1000 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1020 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1040 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1060 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1080 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1100 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1120 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1140 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1160 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1180 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1200 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1220 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1240 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1260 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1280 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1300 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1320 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1340 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1360 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1380 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1400 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1420 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1440 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1460 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1480 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1500 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1520 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1540 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1560 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1580 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1600 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1620 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1640 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1660 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1680 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1700 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1720 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1740 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1760 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1780 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1800 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1820 3.7895614e-14 [1.0000004] [-6.212066e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========step, cost_val, W_val, b_val=====\n",
      "1840 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1860 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1880 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1900 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1920 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1940 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1960 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "1980 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "==========step, cost_val, W_val, b_val=====\n",
      "2000 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
      "=========feed_dict={X: [5]}=============\n",
      "[5.0000014]\n",
      "=========feed_dict={X: [2.5]}=============\n",
      "[2.5000002]\n",
      "=========feed_dict={X: [1.5, 3.5]}))=============\n",
      "[1.4999999 3.5000005]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * W + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.15)\n",
    "train = optimizer.minimize(cost)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train], \n",
    "                 feed_dict={X: [1, 2, 3], Y: [1, 2, 3]})\n",
    "    if step % 20 == 0:\n",
    "        print(\"==========step, cost_val, W_val, b_val=====\")\n",
    "        print(step, cost_val, W_val, b_val)\n",
    "\n",
    "print(\"=========feed_dict={X: [5]}=============\")\n",
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(\"=========feed_dict={X: [2.5]}=============\")\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(\"=========feed_dict={X: [1.5, 3.5]}))=============\")\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step = 20\n",
    "```\n",
    "step = 20\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "0 13.288369 [-0.29553396] [-0.4724274]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "20 0.121346466 [0.84582084] [0.02507534]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "40 0.0018854747 [0.95594823] [0.06915468]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "60 0.0007302738 [0.96781486] [0.07021407]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "80 0.0006543403 [0.9702602] [0.06732462]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "100 0.0005942019 [0.9717466] [0.06419967]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "120 0.0005396614 [0.97308296] [0.06118624]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "140 0.0004901315 [0.9743487] [0.05831107]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "160 0.00044514347 [0.97555435] [0.05557071]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "180 0.00040428768 [0.97670317] [0.0529591]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "200 0.0003671817 [0.97779804] [0.05047024]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "220 0.00033348193 [0.9788414] [0.04809835]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "240 0.00030287384 [0.9798356] [0.04583799]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "260 0.00027507325 [0.9807835] [0.04368376]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "280 0.00024982673 [0.9816866] [0.04163074]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "300 0.00022689575 [0.9825473] [0.03967422]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "320 0.00020607124 [0.98336744] [0.03780967]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "340 0.00018715672 [0.98414916] [0.03603275]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "360 0.00016997811 [0.98489416] [0.03433931]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "380 0.00015437823 [0.98560405] [0.03272545]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "400 0.00014020682 [0.98628056] [0.03118748]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "420 0.00012733859 [0.98692536] [0.02972179]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "440 0.00011564984 [0.9875398] [0.02832496]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "460 0.00010503468 [0.9881254] [0.02699377]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "480 9.5395946e-05 [0.98868346] [0.02572516]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "500 8.664e-05 [0.9892152] [0.0245162]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "520 7.868841e-05 [0.98972213] [0.02336403]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "540 7.146429e-05 [0.9902053] [0.02226595]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "560 6.490495e-05 [0.99066556] [0.02121948]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "580 5.894755e-05 [0.99110425] [0.0202222]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "600 5.3536685e-05 [0.9915223] [0.01927179]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "620 4.8622867e-05 [0.9919207] [0.0183661]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "640 4.4159886e-05 [0.99230045] [0.01750294]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "660 4.0107276e-05 [0.9926623] [0.01668036]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "680 3.6425732e-05 [0.9930071] [0.01589645]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "700 3.3083106e-05 [0.9933357] [0.01514938]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "720 3.0046698e-05 [0.99364895] [0.01443741]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "740 2.728796e-05 [0.99394745] [0.01375891]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "760 2.4783643e-05 [0.9942319] [0.01311229]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "780 2.2508806e-05 [0.9945029] [0.01249607]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "800 2.0442982e-05 [0.9947612] [0.01190883]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "820 1.856673e-05 [0.9950074] [0.01134921]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "840 1.6862628e-05 [0.9952421] [0.01081584]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "860 1.5315005e-05 [0.9954657] [0.01030753]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "880 1.3909636e-05 [0.9956788] [0.00982311]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "900 1.263285e-05 [0.99588186] [0.00936148]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "920 1.1473053e-05 [0.9960754] [0.00892153]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "940 1.0420663e-05 [0.9962598] [0.00850227]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "960 9.464226e-06 [0.9964356] [0.00810269]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "980 8.595252e-06 [0.9966031] [0.00772192]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1000 7.8066205e-06 [0.9967627] [0.00735905]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1020 7.0901237e-06 [0.99691486] [0.00701323]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1040 6.4390806e-06 [0.9970598] [0.00668364]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1060 5.8483315e-06 [0.997198] [0.00636956]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1080 5.311618e-06 [0.9973297] [0.00607024]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1100 4.8240404e-06 [0.9974552] [0.00578496]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1120 4.3813016e-06 [0.99757475] [0.00551309]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1140 3.979032e-06 [0.9976888] [0.005254]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1160 3.6137535e-06 [0.99779737] [0.00500707]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1180 3.282186e-06 [0.9979009] [0.00477175]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1200 2.9808982e-06 [0.9979995] [0.00454751]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1220 2.7072429e-06 [0.99809355] [0.0043338]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1240 2.4587478e-06 [0.99818313] [0.00413012]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1260 2.2331108e-06 [0.9982685] [0.00393603]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1280 2.0283114e-06 [0.9983499] [0.00375107]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1300 1.8419613e-06 [0.99842745] [0.00357479]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1320 1.6729592e-06 [0.99850136] [0.0034068]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1340 1.5194445e-06 [0.99857175] [0.00324671]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1360 1.3800912e-06 [0.99863887] [0.00309413]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1380 1.2532952e-06 [0.9987028] [0.00294873]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1400 1.138403e-06 [0.99876374] [0.00281018]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1420 1.0338407e-06 [0.99882185] [0.00267813]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1440 9.389278e-07 [0.99887717] [0.0025523]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1460 8.527798e-07 [0.99893] [0.00243239]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1480 7.7450903e-07 [0.9989802] [0.0023181]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1500 7.035908e-07 [0.9990281] [0.00220917]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1520 6.3886506e-07 [0.99907386] [0.00210538]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1540 5.8032634e-07 [0.9991174] [0.00200644]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1560 5.2704655e-07 [0.9991588] [0.00191214]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1580 4.7867485e-07 [0.9991984] [0.00182231]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1600 4.347643e-07 [0.999236] [0.00173669]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1620 3.948202e-07 [0.9992719] [0.0016551]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1640 3.5860717e-07 [0.999306] [0.00157735]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1660 3.2582957e-07 [0.9993387] [0.00150326]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1680 2.9585397e-07 [0.9993698] [0.00143263]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1700 2.6871479e-07 [0.9993993] [0.00136533]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1720 2.4409027e-07 [0.9994275] [0.00130121]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1740 2.2163562e-07 [0.99945444] [0.00124009]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1760 2.0133223e-07 [0.99948] [0.00118183]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1780 1.8286438e-07 [0.9995044] [0.00112634]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1800 1.6611837e-07 [0.9995277] [0.00107345]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1820 1.5088625e-07 [0.99954987] [0.00102304]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1840 1.3703813e-07 [0.999571] [0.000975]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1860 1.2449529e-07 [0.99959123] [0.00092924]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1880 1.1307293e-07 [0.99961036] [0.00088563]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1900 1.0265675e-07 [0.9996286] [0.00084404]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1920 9.3276185e-08 [0.99964607] [0.0008044]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1940 8.47452e-08 [0.99966276] [0.00076666]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1960 7.69675e-08 [0.99967843] [0.00073068]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1980 6.9909824e-08 [0.99969363] [0.00069637]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "2000 6.349562e-08 [0.99970794] [0.00066373]\n",
    "=========feed_dict={X: [5]}=============\n",
    "[4.9992037]\n",
    "=========feed_dict={X: [2.5]}=============\n",
    "[2.4999337]\n",
    "=========feed_dict={X: [1.5, 3.5]}))=============\n",
    "[1.5002257 3.4996414]\n",
    "```\n",
    "\n",
    "#### step = 10\n",
    "```\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "0 13.288369 [-0.29553396] [-0.4724274]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "10 1.2661339 [0.57624125] [-0.09125014]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "20 0.121346466 [0.84582084] [0.02507534]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "30 0.0123036755 [0.9295636] [0.05970469]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "40 0.0018854747 [0.95594823] [0.06915468]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "50 0.0008599053 [0.9646206] [0.07086428]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "60 0.0007302738 [0.96781486] [0.07021407]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "70 0.0006874558 [0.96930623] [0.0688637]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "80 0.0006543403 [0.9702602] [0.06732462]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "90 0.00062351354 [0.9710366] [0.06575398]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "100 0.0005942019 [0.9717466] [0.06419967]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "110 0.00056627695 [0.97242516] [0.06267584]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "120 0.0005396614 [0.97308296] [0.06118624]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "130 0.000514304 [0.9737237] [0.05973145]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "140 0.0004901315 [0.9743487] [0.05831107]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "150 0.0004670945 [0.9749588] [0.05692441]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "160 0.00044514347 [0.97555435] [0.05557071]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "170 0.0004242243 [0.9761357] [0.05424919]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "180 0.00040428768 [0.97670317] [0.0529591]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "190 0.00038528675 [0.9772572] [0.05169969]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "200 0.0003671817 [0.97779804] [0.05047024]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "210 0.00034992793 [0.97832596] [0.04927003]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "220 0.00033348193 [0.9788414] [0.04809835]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "230 0.00031781042 [0.9793445] [0.04695456]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "240 0.00030287384 [0.9798356] [0.04583799]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "250 0.00028863916 [0.9803154] [0.04474793]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "260 0.00027507325 [0.9807835] [0.04368376]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "270 0.00026214521 [0.98124045] [0.04264489]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "280 0.00024982673 [0.9816866] [0.04163074]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "290 0.00023808637 [0.9821221] [0.04064071]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "300 0.00022689575 [0.9825473] [0.03967422]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "310 0.00021623181 [0.9829623] [0.03873071]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "320 0.00020607124 [0.98336744] [0.03780967]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "330 0.00019638585 [0.983763] [0.03691052]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "340 0.00018715672 [0.98414916] [0.03603275]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "350 0.00017836038 [0.98452616] [0.03517585]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "360 0.00016997811 [0.98489416] [0.03433931]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "370 0.00016198978 [0.9852534] [0.03352267]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "380 0.00015437823 [0.98560405] [0.03272545]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "390 0.00014712244 [0.98594636] [0.0319472]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "400 0.00014020682 [0.98628056] [0.03118748]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "410 0.00013361806 [0.98660684] [0.03044582]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "420 0.00012733859 [0.98692536] [0.02972179]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "430 0.000121354264 [0.98723626] [0.02901497]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "440 0.00011564984 [0.9875398] [0.02832496]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "450 0.000110214685 [0.9878362] [0.02765135]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "460 0.00010503468 [0.9881254] [0.02699377]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "470 0.00010010023 [0.9884078] [0.02635184]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "480 9.5395946e-05 [0.98868346] [0.02572516]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "490 9.0911904e-05 [0.9889526] [0.02511341]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "500 8.664e-05 [0.9892152] [0.0245162]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "510 8.256786e-05 [0.9894718] [0.0239332]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "520 7.868841e-05 [0.98972213] [0.02336403]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "530 7.498992e-05 [0.98996663] [0.0228084]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "540 7.146429e-05 [0.9902053] [0.02226595]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "550 6.810623e-05 [0.99043816] [0.02173642]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "560 6.490495e-05 [0.99066556] [0.02121948]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "570 6.1854626e-05 [0.9908875] [0.02071483]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "580 5.894755e-05 [0.99110425] [0.0202222]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "590 5.6176974e-05 [0.99131584] [0.01974128]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "600 5.3536685e-05 [0.9915223] [0.01927179]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "610 5.1021078e-05 [0.9917239] [0.0188135]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "620 4.8622867e-05 [0.9919207] [0.0183661]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "630 4.633813e-05 [0.9921129] [0.01792933]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "640 4.4159886e-05 [0.99230045] [0.01750294]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "650 4.2085023e-05 [0.99248356] [0.0170867]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "660 4.0107276e-05 [0.9926623] [0.01668036]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "670 3.822266e-05 [0.9928368] [0.01628369]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "680 3.6425732e-05 [0.9930071] [0.01589645]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "690 3.4713496e-05 [0.9931734] [0.01551841]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "700 3.3083106e-05 [0.9933357] [0.01514938]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "710 3.152755e-05 [0.9934943] [0.01478911]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "720 3.0046698e-05 [0.99364895] [0.01443741]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "730 2.8634153e-05 [0.9938] [0.01409408]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "740 2.728796e-05 [0.99394745] [0.01375891]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "750 2.6006184e-05 [0.9940914] [0.01343171]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "760 2.4783643e-05 [0.9942319] [0.01311229]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "770 2.3619321e-05 [0.99436903] [0.01280047]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "780 2.2508806e-05 [0.9945029] [0.01249607]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "790 2.145161e-05 [0.9946337] [0.01219892]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "800 2.0442982e-05 [0.9947612] [0.01190883]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "810 1.9483085e-05 [0.9948858] [0.01162565]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "820 1.856673e-05 [0.9950074] [0.01134921]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "830 1.7694118e-05 [0.9951262] [0.01107933]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "840 1.6862628e-05 [0.9952421] [0.01081584]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "850 1.6070726e-05 [0.99535525] [0.01055862]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "860 1.5315005e-05 [0.9954657] [0.01030753]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "870 1.4595178e-05 [0.9955735] [0.01006241]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "880 1.3909636e-05 [0.9956788] [0.00982311]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "890 1.3256043e-05 [0.99578154] [0.00958953]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "900 1.263285e-05 [0.99588186] [0.00936148]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "910 1.2039157e-05 [0.9959798] [0.00913885]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "920 1.1473053e-05 [0.9960754] [0.00892153]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "930 1.0934064e-05 [0.99616873] [0.00870938]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "940 1.0420663e-05 [0.9962598] [0.00850227]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "950 9.930448e-06 [0.9963488] [0.00830008]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "960 9.464226e-06 [0.9964356] [0.00810269]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "970 9.01919e-06 [0.99652034] [0.00791002]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "980 8.595252e-06 [0.9966031] [0.00772192]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "990 8.191557e-06 [0.99668384] [0.0075383]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1000 7.8066205e-06 [0.9967627] [0.00735905]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1010 7.4395975e-06 [0.9968397] [0.00718406]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1020 7.0901237e-06 [0.99691486] [0.00701323]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1030 6.756822e-06 [0.99698824] [0.00684645]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1040 6.4390806e-06 [0.9970598] [0.00668364]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1050 6.1365567e-06 [0.99712974] [0.00652471]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1060 5.8483315e-06 [0.997198] [0.00636956]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1070 5.5734563e-06 [0.9972646] [0.00621811]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1080 5.311618e-06 [0.9973297] [0.00607024]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1090 5.0619687e-06 [0.9973932] [0.00592588]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1100 4.8240404e-06 [0.9974552] [0.00578496]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1110 4.5973443e-06 [0.9975157] [0.00564739]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1120 4.3813016e-06 [0.99757475] [0.00551309]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1130 4.1756016e-06 [0.99763244] [0.00538199]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1140 3.979032e-06 [0.9976888] [0.005254]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1150 3.7921354e-06 [0.9977437] [0.00512904]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1160 3.6137535e-06 [0.99779737] [0.00500707]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1170 3.4441534e-06 [0.99784976] [0.004888]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1180 3.282186e-06 [0.9979009] [0.00477175]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1190 3.1279776e-06 [0.9979508] [0.00465828]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1200 2.9808982e-06 [0.9979995] [0.00454751]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1210 2.8406976e-06 [0.9980471] [0.00443938]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1220 2.7072429e-06 [0.99809355] [0.0043338]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1230 2.5799902e-06 [0.9981389] [0.00423073]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1240 2.4587478e-06 [0.99818313] [0.00413012]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1250 2.3432997e-06 [0.99822634] [0.00403191]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1260 2.2331108e-06 [0.9982685] [0.00393603]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1270 2.1282924e-06 [0.9983097] [0.00384245]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1280 2.0283114e-06 [0.9983499] [0.00375107]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1290 1.932999e-06 [0.9983891] [0.00366187]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1300 1.8419613e-06 [0.99842745] [0.00357479]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1310 1.7556763e-06 [0.9984648] [0.00348979]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1320 1.6729592e-06 [0.99850136] [0.0034068]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1330 1.5943561e-06 [0.99853694] [0.00332579]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1340 1.5194445e-06 [0.99857175] [0.00324671]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1350 1.4480917e-06 [0.9986057] [0.00316951]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1360 1.3800912e-06 [0.99863887] [0.00309413]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1370 1.3151111e-06 [0.99867123] [0.00302056]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1380 1.2532952e-06 [0.9987028] [0.00294873]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1390 1.1944522e-06 [0.99873364] [0.00287862]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1400 1.138403e-06 [0.99876374] [0.00281018]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1410 1.0848365e-06 [0.9987932] [0.00274336]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1420 1.0338407e-06 [0.99882185] [0.00267813]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1430 9.853217e-07 [0.99884987] [0.00261446]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1440 9.389278e-07 [0.99887717] [0.0025523]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1450 8.950022e-07 [0.9989039] [0.00249163]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1460 8.527798e-07 [0.99893] [0.00243239]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1470 8.127422e-07 [0.99895537] [0.00237455]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1480 7.7450903e-07 [0.9989802] [0.0023181]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1490 7.381772e-07 [0.9990045] [0.00226298]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1500 7.035908e-07 [0.9990281] [0.00220917]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1510 6.704254e-07 [0.9990513] [0.00215666]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1520 6.3886506e-07 [0.99907386] [0.00210538]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1530 6.08969e-07 [0.9990959] [0.00205532]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1540 5.8032634e-07 [0.9991174] [0.00200644]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1550 5.530475e-07 [0.99913836] [0.00195872]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1560 5.2704655e-07 [0.9991588] [0.00191214]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1570 5.0230193e-07 [0.99917877] [0.00186668]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1580 4.7867485e-07 [0.9991984] [0.00182231]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1590 4.5620618e-07 [0.99921745] [0.00177899]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1600 4.347643e-07 [0.999236] [0.00173669]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1610 4.1433546e-07 [0.9992541] [0.0016954]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1620 3.948202e-07 [0.9992719] [0.0016551]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1630 3.764135e-07 [0.9992892] [0.00161576]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1640 3.5860717e-07 [0.999306] [0.00157735]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1650 3.4178166e-07 [0.9993226] [0.00153985]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1660 3.2582957e-07 [0.9993387] [0.00150326]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1670 3.1048324e-07 [0.99935436] [0.00146751]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1680 2.9585397e-07 [0.9993698] [0.00143263]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1690 2.819518e-07 [0.9993847] [0.00139858]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1700 2.6871479e-07 [0.9993993] [0.00136533]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1710 2.5606775e-07 [0.9994136] [0.00133289]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1720 2.4409027e-07 [0.9994275] [0.00130121]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1730 2.3258593e-07 [0.9994412] [0.00127029]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1740 2.2163562e-07 [0.99945444] [0.00124009]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1750 2.1120401e-07 [0.9994675] [0.0012106]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1760 2.0133223e-07 [0.99948] [0.00118183]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1770 1.9189541e-07 [0.99949247] [0.00115375]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1780 1.8286438e-07 [0.9995044] [0.00112634]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1790 1.7430334e-07 [0.9995163] [0.00109959]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1800 1.6611837e-07 [0.9995277] [0.00107345]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1810 1.583507e-07 [0.999539] [0.00104795]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1820 1.5088625e-07 [0.99954987] [0.00102304]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1830 1.4376111e-07 [0.9995606] [0.00099875]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1840 1.3703813e-07 [0.999571] [0.000975]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1850 1.306156e-07 [0.99958116] [0.00095186]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1860 1.2449529e-07 [0.99959123] [0.00092924]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1870 1.1867203e-07 [0.9996008] [0.00090717]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1880 1.1307293e-07 [0.99961036] [0.00088563]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1890 1.0774687e-07 [0.99961966] [0.00086457]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1900 1.0265675e-07 [0.9996286] [0.00084404]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1910 9.788929e-08 [0.99963754] [0.00082399]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1920 9.3276185e-08 [0.99964607] [0.0008044]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1930 8.8884484e-08 [0.9996544] [0.00078531]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1940 8.47452e-08 [0.99966276] [0.00076666]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1950 8.074753e-08 [0.9996707] [0.00074843]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1960 7.69675e-08 [0.99967843] [0.00073068]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1970 7.332803e-08 [0.9996862] [0.00071334]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1980 6.9909824e-08 [0.99969363] [0.00069637]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "1990 6.665119e-08 [0.9997008] [0.00067985]\n",
    "==========step, cost_val, W_val, b_val=====\n",
    "2000 6.349562e-08 [0.99970794] [0.00066373]\n",
    "=========feed_dict={X: [5]}=============\n",
    "[4.9992037]\n",
    "=========feed_dict={X: [2.5]}=============\n",
    "[2.4999337]\n",
    "=========feed_dict={X: [1.5, 3.5]}))=============\n",
    "[1.5002257 3.4996414]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step = 20\n",
    "2000 6.349562e-08 [0.99970794] [0.00066373]\n",
    "\n",
    "### step = 10\n",
    "2000 6.349562e-08 [0.99970794] [0.00066373]\n",
    "\n",
    "### step = 50\n",
    "2000 6.349562e-08 [0.99970794] [0.00066373]\n",
    "\n",
    "### range(3001)\n",
    "3000 5.343897e-10 [0.99997306] [6.085733e-05]\n",
    "\n",
    "### range(4001)\n",
    "4000 8.436511e-12 [0.9999964] [7.521492e-06]\n",
    "\n",
    "### range(5001)\n",
    "5000 3.0695446e-12 [0.99999785] [4.3504815e-06]\n",
    "\n",
    "\n",
    "### learningrate = 0.01\n",
    "2000 6.349562e-08 [0.99970794] [0.00066373]\n",
    "\n",
    "### learnignrate = 0.05\n",
    "2000 3.7895614e-14 [0.99999976] [5.3116025e-07]\n",
    "\n",
    "### learningrate = 0.5\n",
    "2000 nan [nan] [nan]\n",
    "\n",
    "### learningrate = 0.09\n",
    "2000 3.7895614e-14 [0.99999976] [5.3116025e-07]\n",
    "\n",
    "### learningrate = 0.1\n",
    "**2000 0.0 [1.] [5.6859136e-08]** <br>\n",
    "> 알맞는 learningrate가 있을 때, learningrate보다 큰수보다는 작은수가 좋다?\n",
    "\n",
    "### learningrate = 0.11\n",
    "2000 4.2632564e-14 [0.9999999] [9.263522e-08]\n",
    "\n",
    "### learnignrate = 0.15\n",
    "2000 3.7895614e-14 [1.0000004] [-6.212066e-07]\n",
    "\n",
    "### learningrate = 0.25\n",
    "2000 nan [nan] [nan]<br>\n",
    "==========step, cost_val, W_val, b_val===== <br>\n",
    "140 inf [1.6879146e+35] [7.4251644e+34] <br>\n",
    "==========step, cost_val, W_val, b_val===== <br>\n",
    "160 nan [nan] [nan]\n",
    "\n",
    "### learningrate = 0.2\n",
    "==========step, cost_val, W_val, b_val===== <br>\n",
    "420 inf [1.9818624e+36] [8.7182496e+35] <br>\n",
    "==========step, cost_val, W_val, b_val===== <br>\n",
    "440 nan [nan] [nan]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15.623711 [0.3858341] [0.04400694]\n",
      "20 0.10865022 [1.2091624] [0.33007258]\n",
      "40 0.094608955 [1.1990013] [0.38147542]\n",
      "60 0.0826227 [1.1859845] [0.4285366]\n",
      "80 0.07215501 [1.1738042] [0.47251126]\n",
      "100 0.06301346 [1.1624217] [0.51360613]\n",
      "120 0.0550301 [1.1517845] [0.5520096]\n",
      "140 0.04805824 [1.141844] [0.58789796]\n",
      "160 0.041969582 [1.1325545] [0.62143594]\n",
      "180 0.03665236 [1.1238735] [0.65277755]\n",
      "200 0.03200877 [1.1157608] [0.6820666]\n",
      "220 0.02795344 [1.1081796] [0.7094374]\n",
      "240 0.024411976 [1.1010947] [0.73501563]\n",
      "260 0.021319162 [1.094474] [0.7589188]\n",
      "280 0.018618181 [1.0882868] [0.78125656]\n",
      "300 0.016259387 [1.0825049] [0.80213124]\n",
      "320 0.014199448 [1.0771016] [0.8216388]\n",
      "340 0.0124005 [1.0720521] [0.83986884]\n",
      "360 0.010829445 [1.0673333] [0.8569051]\n",
      "380 0.00945742 [1.0629236] [0.8728258]\n",
      "400 0.00825922 [1.0588027] [0.88770366]\n",
      "420 0.007212843 [1.0549517] [0.90160716]\n",
      "440 0.0062990314 [1.0513529] [0.9146]\n",
      "460 0.0055009765 [1.0479896] [0.9267421]\n",
      "480 0.004804056 [1.0448468] [0.93808883]\n",
      "500 0.004195423 [1.0419097] [0.94869244]\n",
      "520 0.0036638859 [1.0391649] [0.9586019]\n",
      "540 0.0031996928 [1.0366] [0.96786225]\n",
      "560 0.0027943156 [1.034203] [0.976516]\n",
      "580 0.002440301 [1.0319631] [0.984603]\n",
      "600 0.0021311298 [1.0298697] [0.99216044]\n",
      "620 0.0018611338 [1.0279136] [0.9992229]\n",
      "640 0.001625349 [1.0260856] [1.0058227]\n",
      "660 0.0014194228 [1.0243772] [1.0119904]\n",
      "680 0.0012395965 [1.0227808] [1.0177543]\n",
      "700 0.0010825442 [1.0212888] [1.0231408]\n",
      "720 0.0009453927 [1.0198945] [1.0281744]\n",
      "740 0.000825621 [1.0185915] [1.0328784]\n",
      "760 0.00072102173 [1.0173739] [1.0372742]\n",
      "780 0.0006296684 [1.0162362] [1.0413821]\n",
      "800 0.0005498991 [1.0151728] [1.0452211]\n",
      "820 0.00048022595 [1.0141791] [1.0488089]\n",
      "840 0.0004193765 [1.0132505] [1.0521615]\n",
      "860 0.0003662493 [1.0123827] [1.0552944]\n",
      "880 0.00031984525 [1.0115719] [1.0582222]\n",
      "900 0.0002793267 [1.010814] [1.0609583]\n",
      "920 0.00024393895 [1.0101057] [1.0635151]\n",
      "940 0.00021302998 [1.0094438] [1.0659045]\n",
      "960 0.00018604056 [1.0088253] [1.0681376]\n",
      "980 0.0001624684 [1.0082473] [1.0702245]\n",
      "1000 0.00014188341 [1.0077071] [1.0721748]\n",
      "1020 0.00012390628 [1.0072024] [1.0739971]\n",
      "1040 0.00010820861 [1.0067307] [1.0757]\n",
      "1060 9.4499745e-05 [1.0062898] [1.0772914]\n",
      "1080 8.2528284e-05 [1.0058781] [1.0787785]\n",
      "1100 7.207206e-05 [1.005493] [1.0801685]\n",
      "1120 6.294063e-05 [1.0051333] [1.0814673]\n",
      "1140 5.4965385e-05 [1.004797] [1.0826812]\n",
      "1160 4.800143e-05 [1.0044827] [1.0838155]\n",
      "1180 4.191972e-05 [1.0041893] [1.0848753]\n",
      "1200 3.6608577e-05 [1.0039148] [1.0858659]\n",
      "1220 3.1970674e-05 [1.0036585] [1.0867915]\n",
      "1240 2.791965e-05 [1.0034189] [1.0876565]\n",
      "1260 2.4383615e-05 [1.0031949] [1.0884649]\n",
      "1280 2.1294938e-05 [1.0029857] [1.0892203]\n",
      "1300 1.8594217e-05 [1.0027902] [1.0899267]\n",
      "1320 1.6238535e-05 [1.0026073] [1.0905865]\n",
      "1340 1.4181273e-05 [1.0024366] [1.091203]\n",
      "1360 1.2384214e-05 [1.002277] [1.0917792]\n",
      "1380 1.08154145e-05 [1.0021279] [1.0923176]\n",
      "1400 9.444822e-06 [1.0019885] [1.0928206]\n",
      "1420 8.248161e-06 [1.0018584] [1.0932908]\n",
      "1440 7.203767e-06 [1.0017366] [1.0937301]\n",
      "1460 6.291276e-06 [1.0016229] [1.0941406]\n",
      "1480 5.4943935e-06 [1.0015167] [1.0945244]\n",
      "1500 4.7978397e-06 [1.0014173] [1.0948832]\n",
      "1520 4.1900735e-06 [1.0013244] [1.0952183]\n",
      "1540 3.6586582e-06 [1.0012378] [1.0955315]\n",
      "1560 3.195495e-06 [1.0011567] [1.095824]\n",
      "1580 2.7909405e-06 [1.001081] [1.0960974]\n",
      "1600 2.4376393e-06 [1.0010102] [1.0963529]\n",
      "1620 2.128656e-06 [1.0009441] [1.0965917]\n",
      "1640 1.8588823e-06 [1.0008823] [1.096815]\n",
      "1660 1.6236811e-06 [1.0008245] [1.0970235]\n",
      "1680 1.4182827e-06 [1.0007706] [1.0972182]\n",
      "1700 1.2383477e-06 [1.0007201] [1.0974002]\n",
      "1720 1.0816782e-06 [1.000673] [1.0975703]\n",
      "1740 9.4470954e-07 [1.000629] [1.0977294]\n",
      "1760 8.249743e-07 [1.0005877] [1.0978781]\n",
      "1780 7.2070566e-07 [1.0005492] [1.098017]\n",
      "1800 6.294613e-07 [1.0005133] [1.0981467]\n",
      "1820 5.49564e-07 [1.0004797] [1.0982679]\n",
      "1840 4.803166e-07 [1.0004483] [1.0983812]\n",
      "1860 4.193264e-07 [1.0004193] [1.098487]\n",
      "1880 3.6637783e-07 [1.0003917] [1.098586]\n",
      "1900 3.1992855e-07 [1.000366] [1.0986787]\n",
      "1920 2.795607e-07 [1.000342] [1.098765]\n",
      "1940 2.4410863e-07 [1.0003198] [1.0988458]\n",
      "1960 2.131695e-07 [1.0002987] [1.0989214]\n",
      "1980 1.861848e-07 [1.0002793] [1.098992]\n",
      "2000 1.6257832e-07 [1.000261] [1.0990579]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([1]), name='weight') # Variable trainable\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias') # Variable\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None]) \n",
    "# 그래프를 미리 만들어 놓고 실행, 그 때 값을 던져준다. \n",
    "# 특별한 노드 -> 노드값을 몰랐지만 나중에 값을 넣을 수 있다. \n",
    "Y = tf.placeholder(tf.float32, shape=[None]) # 특별한 노드\n",
    "\n",
    "# 수식\n",
    "hypo = X * W + b\n",
    "# 코스트\n",
    "cost = tf.reduce_mean(tf.square(hypo - Y))\n",
    "# 미분 \n",
    "opti = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# 미분을 사용해서? cost function을 최소화?\n",
    "train = opti.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train],\n",
    "                                        feed_dict={X: [1, 2, 3, 4, 5],\n",
    "                                        Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 대략 W = 1, b=1.1 \n",
    "X : [1, 2, 3, 4, 5] Y: [2.1, 3.1, 4.1, 5.1, 6.1] <br>\n",
    "1 \\* 1 + 1.1 = 2.1 <br>\n",
    "2 \\* 1 + 1.1 = 3.1 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습한 값이 잘 수행되는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.100363]\n",
      "[3.5997102]\n",
      "[2.5994494 4.5999713]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypo, feed_dict={X: [5]}))\n",
    "print(sess.run(hypo, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypo, \n",
    "               feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1\n",
      "3.6\n"
     ]
    }
   ],
   "source": [
    "print(5*1+1.1)\n",
    "print(2.5*1+1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5, 3.5]\n",
      "2.6\n",
      "4.6\n",
      "=======index로 접근=======\n",
      "0\n",
      "1.5\n",
      "2.6\n",
      "1\n",
      "3.5\n",
      "4.6\n",
      "List 안의 숫자들은\n",
      "[2.6, 4.6]\n"
     ]
    }
   ],
   "source": [
    "a = [1.5, 3.5]\n",
    "print(a * 1)\n",
    "for i in a:\n",
    "    print(i + 1.1)\n",
    "    \n",
    "print(\"=======index로 접근=======\")    \n",
    "for idx in range(len(a)):\n",
    "    print(idx)\n",
    "    print(a[idx])\n",
    "    print(a[idx]+1.1)\n",
    "    a[idx] = a[idx]+1.1\n",
    "    \n",
    "print(\"List 안의 숫자들은\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
